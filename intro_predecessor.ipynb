{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook explains how to use **Lernd** - my implementation of $\\partial$ILP framework.\n",
    "\n",
    "I will not go into too many details of this implementation here. If interested, I suggest looking at the source code and,\n",
    "especially, unit tests where I used examples straight from the original $\\partial$ILP paper $-$\n",
    "[Learning Explanatory Rules from Noisy Data](https://arxiv.org/abs/1711.04574).\n",
    "\n",
    "Prior to reading this you should be familiar with Inductive Logic Programming (ILP), which is succinctly explained in\n",
    "the original $\\partial$ILP paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### $\\partial$ILP $-$ Differential Inductive Logic Programming Framework\n",
    "Briefly, in $\\partial$ILP all the non-differentiable work is done in advance, producing apparatus for numerical,\n",
    "differentiable forward chaining. Optimization algorithm is run where loss is evaluation of forward chaining results.\n",
    "Automatic differentiation is used to calculate the gradients. Forward chaining is adjusted by the weight matrices, and,\n",
    "in turn, these weights can be adjusted. In the end, results (predicate definitions) are extracted from the weight\n",
    "matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To show how Lernd works, I will walk you through the simple problem of learning the \"predecessor\" relation. Lernd will\n",
    "learn it by using just a few examples and background facts.\n",
    "\n",
    "First the problem needs to expressed in ILP terms. We need to define a language frame and a program template.\n",
    "\n",
    "Formally, a language frame $\\mathcal{L}$ is a tuple $(target, P_e, arity_e, C)$, where $target$ is an intensional target\n",
    "predicate, $P_e$ is a set of extensional predicates, $arity_e$ is an arity map of predicates, $C$ is a set of constants.\n",
    "\n",
    "In Lernd `LanguageModel` corresponds to $\\mathcal{L}$. Here we define a language frame for the predecessor problem:\n",
    "* The $target$ is an intensional predicate we want to learn.\n",
    "* Constants are just natural numbers 0 to 9.\n",
    "* We have 2 extensional predicates, a monadic $zero$ predicate, and a successor relation - a dyadic predicate $succ$.\n",
    "\n",
    "We don't need to worry about $arity_e$ mapping, since arity is part of the predicate definition in this\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from lernd.classes import GroundAtoms, ILP, LanguageModel, MaybeGroundAtom, ProgramTemplate\n",
    "from lernd.lernd_loss import Lernd\n",
    "from lernd.lernd_types import Constant, RuleTemplate\n",
    "from lernd.main import generate_weight_matrices, extract_definitions, print_valuations\n",
    "from lernd.util import ground_atom2str, str2ground_atom, str2pred, get_ground_atom_probs\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "target_pred = str2pred('predecessor/2')\n",
    "zero_pred = str2pred('zero/1')\n",
    "succ_pred = str2pred('succ/2')\n",
    "preds_ext = [zero_pred, succ_pred]\n",
    "constants = [Constant(str(i)) for i in range(10)]\n",
    "language_model = LanguageModel(target_pred, preds_ext, constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Program template $\\Pi$ is a tuple $(P_a, arity_a, rules, T)$ where $P_a$ is a set of invented (auxiliary) intensional\n",
    "predicates, $rules$ - a map of predicate $p$ to a pair of rule templates $(\\tau_p^1, \\tau_p^2)$.\n",
    "\n",
    "Note that in cases where an intensional predicate $p$ is fully expressed in just one clause, rule template $\\tau_p^2$\n",
    "should be $null$ (more on this later).\n",
    "\n",
    "Rule template $\\tau$ is a tuple $(v, int)$, which describes the range of clauses that can be generated ($v$ - a number\n",
    "of existentially quantified variables allowed in the clause, $int \\in \\{0, 1\\}$ - whether intensional predicates are\n",
    "allowed).\n",
    "\n",
    "Program template is actually a hyperparameter, since it needs to be given in advance and is problem specific. It is\n",
    "possible to use iterative deepening (as per $\\partial$ILP paper), but this increases the amount of computation\n",
    "massively. Iterative deepening is currently not implemented in Lernd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds_aux = []\n",
    "rules = {target_pred: (RuleTemplate((0, False)), None)}\n",
    "forward_chaining_steps = 1\n",
    "program_template = ProgramTemplate(preds_aux, rules, forward_chaining_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Background axioms (ground atoms), positive and negative examples are also part of the ILP problem definition.\n",
    "\n",
    "Define background axioms - $zero(0)$ and $succ$ examples, as well as positive examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background axioms:\n",
      "zero(0)\n",
      "succ(0,1)\n",
      "succ(1,2)\n",
      "succ(2,3)\n",
      "succ(3,4)\n",
      "succ(4,5)\n",
      "succ(5,6)\n",
      "succ(6,7)\n",
      "succ(7,8)\n",
      "succ(8,9)\n",
      "\n",
      "Positive examples:\n",
      "predecessor(1,0)\n",
      "predecessor(2,1)\n",
      "predecessor(3,2)\n",
      "predecessor(4,3)\n",
      "predecessor(5,4)\n",
      "predecessor(6,5)\n",
      "predecessor(7,6)\n",
      "predecessor(8,7)\n",
      "predecessor(9,8)\n"
     ]
    }
   ],
   "source": [
    "ground_zero = str2ground_atom('zero(0)')\n",
    "background_axioms = [ground_zero] + [str2ground_atom(f'succ({i},{i + 1})') for i in range(9)]\n",
    "positive_examples = [str2ground_atom(f'predecessor({i + 1},{i})') for i in range(9)]\n",
    "print('Background axioms:')\n",
    "print('\\n'.join(map(ground_atom2str, background_axioms)))\n",
    "print('\\nPositive examples:')\n",
    "print('\\n'.join(map(ground_atom2str, positive_examples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this case, negative examples are all other $predecessor$ substitutions ($\\mathcal{P}$ being a set of positive\n",
    "examples):\n",
    "\n",
    "$\\mathcal{N} = \\{predecessor(X,Y) \\mid (X,Y) \\in \\{0,\\ldots,9\\}^2\\} - \\mathcal{P}$\n",
    "\n",
    "Here I take advantage of Lernd's `ground_atom_generator` to define it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative examples:\n",
      "predecessor(0,0)\n",
      "predecessor(0,1)\n",
      "predecessor(0,2)\n",
      "predecessor(0,3)\n",
      "predecessor(0,4)\n",
      "predecessor(0,5)\n",
      "predecessor(0,6)\n",
      "predecessor(0,7)\n",
      "predecessor(0,8)\n",
      "predecessor(0,9)\n",
      "predecessor(1,1)\n",
      "predecessor(1,2)\n",
      "predecessor(1,3)\n",
      "predecessor(1,4)\n",
      "predecessor(1,5)\n",
      "predecessor(1,6)\n",
      "predecessor(1,7)\n",
      "predecessor(1,8)\n",
      "predecessor(1,9)\n",
      "predecessor(2,0)\n",
      "predecessor(2,2)\n",
      "predecessor(2,3)\n",
      "predecessor(2,4)\n",
      "predecessor(2,5)\n",
      "predecessor(2,6)\n",
      "predecessor(2,7)\n",
      "predecessor(2,8)\n",
      "predecessor(2,9)\n",
      "predecessor(3,0)\n",
      "predecessor(3,1)\n",
      "predecessor(3,3)\n",
      "predecessor(3,4)\n",
      "predecessor(3,5)\n",
      "predecessor(3,6)\n",
      "predecessor(3,7)\n",
      "predecessor(3,8)\n",
      "predecessor(3,9)\n",
      "predecessor(4,0)\n",
      "predecessor(4,1)\n",
      "predecessor(4,2)\n",
      "predecessor(4,4)\n",
      "predecessor(4,5)\n",
      "predecessor(4,6)\n",
      "predecessor(4,7)\n",
      "predecessor(4,8)\n",
      "predecessor(4,9)\n",
      "predecessor(5,0)\n",
      "predecessor(5,1)\n",
      "predecessor(5,2)\n",
      "predecessor(5,3)\n",
      "predecessor(5,5)\n",
      "predecessor(5,6)\n",
      "predecessor(5,7)\n",
      "predecessor(5,8)\n",
      "predecessor(5,9)\n",
      "predecessor(6,0)\n",
      "predecessor(6,1)\n",
      "predecessor(6,2)\n",
      "predecessor(6,3)\n",
      "predecessor(6,4)\n",
      "predecessor(6,6)\n",
      "predecessor(6,7)\n",
      "predecessor(6,8)\n",
      "predecessor(6,9)\n",
      "predecessor(7,0)\n",
      "predecessor(7,1)\n",
      "predecessor(7,2)\n",
      "predecessor(7,3)\n",
      "predecessor(7,4)\n",
      "predecessor(7,5)\n",
      "predecessor(7,7)\n",
      "predecessor(7,8)\n",
      "predecessor(7,9)\n",
      "predecessor(8,0)\n",
      "predecessor(8,1)\n",
      "predecessor(8,2)\n",
      "predecessor(8,3)\n",
      "predecessor(8,4)\n",
      "predecessor(8,5)\n",
      "predecessor(8,6)\n",
      "predecessor(8,8)\n",
      "predecessor(8,9)\n",
      "predecessor(9,0)\n",
      "predecessor(9,1)\n",
      "predecessor(9,2)\n",
      "predecessor(9,3)\n",
      "predecessor(9,4)\n",
      "predecessor(9,5)\n",
      "predecessor(9,6)\n",
      "predecessor(9,7)\n",
      "predecessor(9,9)\n"
     ]
    }
   ],
   "source": [
    "ground_atoms = GroundAtoms(language_model, program_template)\n",
    "negative_examples = []\n",
    "for ground_atom, _ in ground_atoms.ground_atom_generator(MaybeGroundAtom.from_pred(target_pred)):\n",
    "    if ground_atom not in positive_examples:\n",
    "        negative_examples.append(ground_atom)\n",
    "print('Negative examples:')\n",
    "print('\\n'.join(map(ground_atom2str, negative_examples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All of that together constitutes an ILP problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ilp_problem = ILP(language_model, background_axioms, positive_examples, negative_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can initialize `Lernd`. On initialization it will perform all the non-differentiable operations, mainly the\n",
    "generation of $X_c$ tensors (one for each generated clause). These tensors hold indices of ground atoms that satisfy the\n",
    "clause, and thus enable forward chaining. For more details, see the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating clauses...\n",
      "Generating ground atoms...\n",
      "Making big lambda...\n",
      "Generating initial valuation...\n",
      "Initializing Inferrer\n",
      "Inferrer initializing xc tensors...\n"
     ]
    }
   ],
   "source": [
    "lernd_model = Lernd(ilp_problem, program_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to start the training. We initialize the weights.\n",
    "\n",
    "We are using `RMSProp` optimization as suggested in the paper. All other hyperparameter values are also taken from the\n",
    "paper. The only exceptions are the number of steps (100 here instead of 6000) and `clause_prob_threshold` (which is the\n",
    "probability needed for us to extract the clauses). If it does not reach the set 0.1, I extract clauses with max\n",
    "probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/crunch/.conda/envs/lernd/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:644: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "Step 10 loss: 0.002441584365442395\n",
      "\n",
      "Step 20 loss: 0.0008735893061384559\n",
      "\n",
      "Step 30 loss: 0.000420353258959949\n",
      "\n",
      "Step 40 loss: 0.0002241743786726147\n",
      "\n",
      "Step 50 loss: 0.00012535670248325914\n",
      "\n",
      "Step 60 loss: 7.185238064266741e-05\n",
      "\n",
      "Step 70 loss: 4.174029527348466e-05\n",
      "\n",
      "Step 80 loss: 2.4436507374048233e-05\n",
      "\n",
      "Step 90 loss: 1.4375813407241367e-05\n",
      "\n",
      "Step 100 loss: 8.478499694319908e-06\n",
      "\n",
      "Step 110 loss: 5.015251190343406e-06\n",
      "\n",
      "Step 120 loss: 2.9617956442962168e-06\n",
      "\n",
      "Step 130 loss: 1.7607358131499495e-06\n",
      "\n",
      "Step 140 loss: 1.0436824595672078e-06\n",
      "\n",
      "Step 150 loss: 6.306190130089817e-07\n",
      "\n",
      "Step 160 loss: 3.749138670627872e-07\n",
      "\n",
      "Step 170 loss: 2.2292158519121585e-07\n",
      "\n",
      "Step 180 loss: 1.4126310077244852e-07\n",
      "\n",
      "Step 190 loss: 9.17911862075016e-08\n",
      "\n",
      "Step 200 loss: 5.96046660916727e-08\n",
      "\n",
      "Step 210 loss: 3.3378604769040976e-08\n",
      "\n",
      "Step 220 loss: 2.2053722403825304e-08\n",
      "\n",
      "Step 230 loss: 2.1457676524505587e-08\n",
      "\n",
      "Step 240 loss: 1.0728836485895954e-08\n",
      "\n",
      "Step 250 loss: 1.0728836485895954e-08\n",
      "\n",
      "Step 260 loss: -0.0\n",
      "\n",
      "Step 270 loss: -0.0\n",
      "\n",
      "Step 280 loss: -0.0\n",
      "\n",
      "Step 290 loss: -0.0\n",
      "\n",
      "Step 300 loss: -0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = generate_weight_matrices(lernd_model.clauses)\n",
    "losses = []\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.5)\n",
    "\n",
    "im = None\n",
    "for i in range(1, 301):\n",
    "    loss_grad, loss, valuation, _ = lernd_model.grad(weights)\n",
    "    optimizer.apply_gradients(zip(loss_grad, list(weights.values())))\n",
    "    loss_float = float(loss.numpy())\n",
    "    losses.append(loss_float)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Step {i} loss: {loss_float}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's plot the loss to see how it went. Basically, this simple problem is solved in under 10 training steps, and if run\n",
    "for 300 steps, loss converges to exactly 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Value')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses)\n",
    "ax.set_title('Loss')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally let's extract the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clause_prob_threshold: 0.1\n",
      "\n",
      "Clause learnt:\n",
      "With probability (confidence): 1.0\n",
      "predecessor(A,B)<-succ(B,A), succ(B,A)\n",
      "\n",
      "Valuations of ground atoms (only those >0.01 for readability):\n",
      "zero(0) - 1.0\n",
      "succ(0,1) - 1.0\n",
      "succ(1,2) - 1.0\n",
      "succ(2,3) - 1.0\n",
      "succ(3,4) - 1.0\n",
      "succ(4,5) - 1.0\n",
      "succ(5,6) - 1.0\n",
      "succ(6,7) - 1.0\n",
      "succ(7,8) - 1.0\n",
      "succ(8,9) - 1.0\n",
      "predecessor(1,0) - 1.0\n",
      "predecessor(2,1) - 1.0\n",
      "predecessor(3,2) - 1.0\n",
      "predecessor(4,3) - 1.0\n",
      "predecessor(5,4) - 1.0\n",
      "predecessor(6,5) - 1.0\n",
      "predecessor(7,6) - 1.0\n",
      "predecessor(8,7) - 1.0\n",
      "predecessor(9,8) - 1.0\n"
     ]
    }
   ],
   "source": [
    "extract_definitions(lernd_model.clauses, weights)\n",
    "ground_atom_probs = get_ground_atom_probs(valuation, lernd_model.ground_atoms)\n",
    "print_valuations(ground_atom_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obviously, this is a simple problem with no noise in the data, so the next notebook (`even.ipynb`) will demonstrate how\n",
    "**Lernd** solves a more difficult problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}